{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55bca6d-cb6b-4ec1-bbad-9448b147967c",
   "metadata": {},
   "source": [
    "In this notebook different quantisation methods and distance metrics for Facial Recognition will be compared both on accuracy and execution time. \n",
    "\n",
    "The Quantisation methods include:\n",
    "- Scalar Quantisation\n",
    "- TensorFlow Quantisation\n",
    "\n",
    "The distance metrics include:\n",
    "- Cosine Similarity\n",
    "- Euclidean Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a699d2ca-b77e-4f7d-8ff3-d0cedef542fd",
   "metadata": {},
   "source": [
    "Below are the necassary import to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab3d98-13d1-46ec-b5d4-fda1f58c7092",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # suppress tensorflow warnings https://stackoverflow.com/a/40871012\n",
    "from deepface import DeepFace\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from decimal import Decimal # for proper rounding\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import struct\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import statistics\n",
    "import accuracy as ac\n",
    "import pickle\n",
    "import quantisations as qt\n",
    "\n",
    "\n",
    "import basics as bs\n",
    "\n",
    "\n",
    "# CONSTANTS\n",
    "EXECUTABLE_PATH = \"ABY/build/bin\"\n",
    "INPUT_FILE_NAME = \"input_vecs.txt\"\n",
    "EXECUTABLE_NAME_SCENARIO = 'cos_dist_copy'\n",
    "CMD_SCENARIO = f\"./{EXECUTABLE_NAME_SCENARIO} -r 1 -f {INPUT_FILE_NAME} & (./{EXECUTABLE_NAME_SCENARIO} -r 0 -f {INPUT_FILE_NAME} 2>&1 > /dev/null)\"\n",
    "\n",
    "# random number generator\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316b1680-eeee-43a6-9a23-98021e2251ec",
   "metadata": {},
   "source": [
    "Below are two functions to compare Facenet and Sface accuracy. One for Euclidean Distance and one for Cosine Similarity. The code to create a visual representation for this comparison is also included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956e56f4-0543-436e-a677-2edc2bd4c78a",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "###### GENERATING THE GLOBAL PAIRS. \n",
    "######## we only need to run this once and then we can have the file and use pairs as the list of embeddings \n",
    "########## uncomment to use for first them, then use the next cell!\n",
    "\n",
    "##########!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!##########\n",
    "## IF U GENERATE A NEW FILE, CHANGE THE NAME!!!! THE EMBEDINGPAIRS.PKL IS THE WORKING ONE AND THE ONE USED!!!!!!!!!!!!!!!!!!!##########\n",
    "##########!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!##########\n",
    "\n",
    "# #\n",
    "# # Generate pairs globally\n",
    "def generate_pairs(m):\n",
    "    pairs = []\n",
    "    for _ in range(m):\n",
    "        n = random.choice([True, False])\n",
    "        imga, imgb = bs.get_two_random_images(same_person=n)\n",
    "        pairs.append((imga, imgb,n))\n",
    "    return pairs\n",
    "\n",
    "# m = 2000\n",
    "# pairs = generate_pairs(m)\n",
    "\n",
    "#File path\n",
    "file_path = 'embedingpairs.pkl'\n",
    "\n",
    "# # Delete the file if it exists\n",
    "# if os.path.exists(file_path):\n",
    "#     os.remove(file_path)\n",
    "\n",
    "# # Save pairs to a new file\n",
    "# with open(file_path, 'wb') as file:\n",
    "#     pickle.dump(pairs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73af373-c771-4617-a869-09209e148aeb",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "with open(file_path, 'rb') as file:\n",
    "    pairs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f730dee",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Running the comparison functions\n",
    "\n",
    "counters_euc,times_euc = ac.compare_accuracies_euc(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed6f3a0-f691-4e4e-8582-8aab97932749",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "counters_cos,times_cos_facenet,times_cos_sface = ac.compare_accuracies_cos(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22db7820-c806-4465-b612-d8fe9793dab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(times_cos_facenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6352d83-5c03-41e7-86be-f0121d1f5c35",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "counters_euc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa68048-0750-4208-a80f-5d2e2ac05d54",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "counters_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ca034a-f184-4b66-bf70-4e3c47119b04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = 1000  # Number of iterations\n",
    "Execution_facenet = []\n",
    "Execution_sface = []\n",
    "failed_retrieval_facenet=0\n",
    "failed_retrieval_sface=0\n",
    "for i in range(m):\n",
    "    n = random.choice([True, False])\n",
    "    _, b = bs.get_two_random_images(n)  # We only need the second image 'b' for sface in this context\n",
    "\n",
    "    # Retry mechanism for FaceNet embedding\n",
    "    while True:\n",
    "        try:\n",
    "            a, _ = bs.get_two_random_images(n)  # We need the first image 'a' for FaceNet\n",
    "            start_time = time.time()\n",
    "            a_embedding = bs.get_embedding_facenet(a)\n",
    "            end_time = time.time()\n",
    "            execution_facenet = end_time - start_time\n",
    "            Execution_facenet.append(execution_facenet)\n",
    "            break  # Exit the loop if successful\n",
    "        except Exception as e:\n",
    "            failed_retrieval_facenet+=1\n",
    "\n",
    "    # Retry mechanism for SFace embedding\n",
    "    while True:\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            b_embedding = bs.get_embedding(b)\n",
    "            end_time = time.time()\n",
    "            execution_sface = end_time - start_time\n",
    "            Execution_sface.append(execution_sface)\n",
    "            break  # Exit the loop if successful\n",
    "        except Exception as e:\n",
    "            failed_retrieval_sface+=1\n",
    "\n",
    "    print(f\"Iteration {i+1}/{m} completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56ce9f4-9409-43dd-8454-c617b82ec9d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "people = [p for p in os.listdir('lfw') if os.path.isdir(os.path.join('lfw', p))] # list of all people that have images\n",
    "m=1000\n",
    "Execution_facenet=[]\n",
    "Execution_sface=[]\n",
    "failed_retrieval_sface=0\n",
    "failed_retrieval_facenet=0\n",
    "for i in range(m,2*m):\n",
    "    print(f\"Iteration {i+1}/{m} completed.\")\n",
    "    try:\n",
    "        person1=people[i]\n",
    "        img1 = f\"lfw/{person1}/{random.choice(os.listdir(f'lfw/{person1}'))}\"\n",
    "        start_time = time.time()\n",
    "        a_embedding = bs.get_embedding_facenet(img1)\n",
    "        end_time = time.time()\n",
    "        execution_facenet = end_time - start_time\n",
    "        Execution_facenet.append(execution_facenet)\n",
    "    except Exception as e:\n",
    "        failed_retrieval_facenet+=1\n",
    "\n",
    "# Retry mechanism for SFace embedding\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        b_embedding = bs.get_embedding(img1)\n",
    "        end_time = time.time()\n",
    "        execution_sface = end_time - start_time\n",
    "        Execution_sface.append(execution_sface)\n",
    "    except Exception as e:\n",
    "        failed_retrieval_sface+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ae0253-7c3c-4056-b4db-a96a948fe0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Execution_facenet_avg=sum(Execution_facenet)/len(Execution_facenet)\n",
    "Execution_sface_avg=sum(Execution_sface)/len(Execution_sface)\n",
    "print(\"Execution_facenet_avg:\",Execution_facenet_avg,\"Execution_sface_avg:\",Execution_sface_avg)\n",
    "print(\"facenet failed:\",failed_retrieval_facenet,\"sface failed:\",failed_retrieval_sface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d4d38d-42c2-41cf-8766-edd4f7016385",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "m=1000\n",
    "# Calculate and print the average execution times\n",
    "print(\"Average Execution Times (in seconds):\")\n",
    "for name in times_euc.keys():\n",
    "    avg_tensor_time_euc = times_euc[name]['tensor_time'] / m  # Assuming m=1000\n",
    "    avg_scalar_time_euc = times_euc[name]['scalar_time'] / m\n",
    "    \n",
    "    avg_tensor_time_cos = times_cos[name]['tensor_time'] / m\n",
    "    avg_scalar_time_cos = times_cos[name]['scalar_time'] / m\n",
    "\n",
    "    print(f\"\\nQuantization Method: {name}\")\n",
    "    # print(f\"  Total Tensor Time (Euclidean): {times_euc[name]['tensor_time']} seconds\")\n",
    "    # print(f\"  Total Scalar Time (Euclidean): {times_euc[name]['scalar_time']} seconds\")\n",
    "    print(f\"  Average Tensor Time (Euclidean): {avg_tensor_time_euc:.6f} seconds\")\n",
    "    print(f\"  Average Scalar Time (Euclidean): {avg_scalar_time_euc:.6f} seconds\")\n",
    "    \n",
    "    # print(f\"  Total Tensor Time (Cosine): {times_cos[name]['tensor_time']} seconds\")\n",
    "    # print(f\"  Total Scalar Time (Cosine): {times_cos[name]['scalar_time']} seconds\")\n",
    "    print(f\"  Average Tensor Time (Cosine): {avg_tensor_time_cos:.6f} seconds\")\n",
    "    print(f\"  Average Scalar Time (Cosine): {avg_scalar_time_cos:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dfd6b5-7d11-4b2c-8075-05fbbea36e7e",
   "metadata": {},
   "source": [
    "below will be the functions to compare the execution time of (Facenet, SFace) x (Euclidean, Cosine) X (no quantisation, Tensorflow, scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618bbe94-04f9-4dd8-b1ac-272e5cc70b55",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Provided data\n",
    "data = {\n",
    "    'quant methods': {\n",
    "        'correct_tensorflow_facenet': 544, 'wrong_tensorflow_facenet': 466,\n",
    "        'correct_scalar_max_facenet': 554, 'wrong_scalar_max_facenet': 466,\n",
    "        'correct_noquant_facenet': 768, 'wrong_noquant_facenet': 232,\n",
    "        'correct_tensorflow_sface': 554, 'wrong_tensorflow_sface': 446,\n",
    "        'correct_scalar_max_sface': 555, 'wrong_scalar_max_sface': 445,\n",
    "        'correct_noquant_sface': 841, 'wrong_noquant_sface': 159,\n",
    "        'correct_scalar_percentile_facenet': 555, 'wrong_scalar_percentile_facenet': 445,\n",
    "        'correct_scalar_percentile_sface': 550, 'wrong_scalar_percentile_sface': 450,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Extract metrics and labels\n",
    "metrics = [\n",
    "    'tensorflow_facenet', 'scalar_max_facenet', 'scalar_percentile_facenet', 'noquant_facenet',\n",
    "    'tensorflow_sface', 'scalar_max_sface', 'scalar_percentile_sface', 'noquant_sface'\n",
    "]\n",
    "\n",
    "# Initialize lists to hold the bar heights and percentages\n",
    "correct_counts = []\n",
    "wrong_counts = []\n",
    "correct_percentages = []\n",
    "wrong_percentages = []\n",
    "\n",
    "# Calculate counts and percentages for each metric in each category\n",
    "for metric in metrics:\n",
    "    correct = data['quant methods'][f'correct_{metric}']\n",
    "    wrong = data['quant methods'][f'wrong_{metric}']\n",
    "    total = correct + wrong\n",
    "    correct_counts.append(correct)\n",
    "    wrong_counts.append(wrong)\n",
    "    correct_percentages.append((correct / total) * 100)\n",
    "    wrong_percentages.append((wrong / total) * 100)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(metrics))\n",
    "\n",
    "# Plot bars for correct and wrong counts\n",
    "bars_correct = ax.bar(index, correct_counts, bar_width, label='Correct', color='#4CAF50')\n",
    "bars_wrong = ax.bar(index + bar_width, wrong_counts, bar_width, label='Wrong', color='#F44336')\n",
    "\n",
    "# Annotate bars with percentages\n",
    "for bars, percentages in zip([bars_correct, bars_wrong], [correct_percentages, wrong_percentages]):\n",
    "    for bar, percentage in zip(bars, percentages):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, height, f'{percentage:.1f}%', ha='center', va='bottom', fontsize=12, color='black', weight='bold')\n",
    "\n",
    "# Customizing the plot\n",
    "ax.set_xlabel('Metrics', fontsize=12)\n",
    "ax.set_ylabel('Counts', fontsize=12)\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels([metric.replace('_', '\\n') for metric in metrics], rotation=45, ha='right', fontsize=12)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153d03f7-2e21-4bab-9b53-30a1a7ea4013",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "data = counters_euc\n",
    "\n",
    "# Convert to DataFrame\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "# Adding actual values to the top of the bars\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# First plot: scalar_quantisation_max\n",
    "ax1 = df['scalar_quantisation_max'].plot(kind='bar', ax=axes[0], color=['blue', 'red', 'green', 'orange', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan', 'yellow', 'magenta'])\n",
    "axes[0].set_title('Scalar Quantisation Max')\n",
    "axes[0].set_ylabel('Counts')\n",
    "axes[0].set_xlabel('Categories')\n",
    "\n",
    "# Adding values on top of the bars\n",
    "for p in ax1.patches:\n",
    "    ax1.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))\n",
    "\n",
    "# Second plot: scalar_quantisation_percentile\n",
    "ax2 = df['scalar_quantisation_percentile'].plot(kind='bar', ax=axes[1], color=['blue', 'red', 'green', 'orange', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan', 'yellow', 'magenta'])\n",
    "axes[1].set_title('Scalar Quantisation Percentile')\n",
    "axes[1].set_ylabel('Counts')\n",
    "axes[1].set_xlabel('Categories')\n",
    "\n",
    "# Adding values on top of the bars\n",
    "for p in ax2.patches:\n",
    "    ax2.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfa44cb-e00a-4ef2-a4e8-ba87eac82850",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
