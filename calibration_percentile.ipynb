{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55bca6d-cb6b-4ec1-bbad-9448b147967c",
   "metadata": {},
   "source": [
    "In this notebook different quantisation methods and distance metrics for Facial Recognition will be compared both on accuracy and execution time. \n",
    "\n",
    "The Quantisation methods include:\n",
    "- Scalar Quantisation\n",
    "- TensorFlow Quantisation\n",
    "\n",
    "The distance metrics include:\n",
    "- Cosine Similarity\n",
    "- Euclidean Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a699d2ca-b77e-4f7d-8ff3-d0cedef542fd",
   "metadata": {},
   "source": [
    "Below are the necassary import to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37ab3d98-13d1-46ec-b5d4-fda1f58c7092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # suppress tensorflow warnings https://stackoverflow.com/a/40871012\n",
    "from deepface import DeepFace\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from decimal import Decimal # for proper rounding\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import struct\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import statistics\n",
    "import accuracy as ac\n",
    "import pickle\n",
    "import quantisations as qt\n",
    "import basics as bs\n",
    "\n",
    "\n",
    "# CONSTANTS\n",
    "EXECUTABLE_PATH = \"ABY/build/bin\"\n",
    "INPUT_FILE_NAME = \"input_vecs.txt\"\n",
    "EXECUTABLE_NAME_SCENARIO = 'cos_dist_copy'\n",
    "CMD_SCENARIO = f\"./{EXECUTABLE_NAME_SCENARIO} -r 1 -f {INPUT_FILE_NAME} & (./{EXECUTABLE_NAME_SCENARIO} -r 0 -f {INPUT_FILE_NAME} 2>&1 > /dev/null)\"\n",
    "\n",
    "# random number generator\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3253443-22b2-4600-8762-01d70057a928",
   "metadata": {},
   "source": [
    "Here we test if quantisation works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c43bae1-cad9-4589-af0b-b55ba7470d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size before scalar quantisation: 1080 , size after scalar quantisation: 240\n",
      "size before tensor quantisation: 1080 , size after tensor quantisation: 240\n",
      "the type of the elements in the scalar quantisation is: <class 'numpy.int8'> in the non quantised embedding it was: <class 'float'>\n",
      "the type of the elements in the tensor quantisation is: <class 'numpy.int8'> in the non quantised embedding it was: <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "embedding1 = bs.get_embedding(\"lfw/George_W_Bush/George_W_Bush_0001.jpg\")\n",
    "embedding2 = bs.get_embedding(\"lfw/George_W_Bush/George_W_Bush_0002.jpg\")\n",
    "bs.get_cos_dist_numpy(embedding1, embedding2)\n",
    "# print(embedding1)\n",
    "embedding1_quant=qt.scalar_quantisation_percentile(embedding1)\n",
    "embedding2_quant=qt.quantize_tensor(embedding2)\n",
    "print(\"size before scalar quantisation:\" ,sys.getsizeof(embedding1), \", size after scalar quantisation:\",sys.getsizeof(embedding1_quant)) \n",
    "print(\"size before tensor quantisation:\", sys.getsizeof(embedding2), \", size after tensor quantisation:\",sys.getsizeof(embedding2_quant)) \n",
    "print(\"the type of the elements in the scalar quantisation is:\", type(embedding1_quant[0]), \"in the non quantised embedding it was:\",type(embedding1[0]))\n",
    "print(\"the type of the elements in the tensor quantisation is:\", type(embedding2_quant[0]), \"in the non quantised embedding it was:\",type(embedding2[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316b1680-eeee-43a6-9a23-98021e2251ec",
   "metadata": {},
   "source": [
    "Below are two functions to compare Facenet and Sface accuracy. One for Euclidean Distance and one for Cosine Similarity. The code to create a visual representation for this comparison is also included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "956e56f4-0543-436e-a677-2edc2bd4c78a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pairs\n\u001b[1;32m     16\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m---> 17\u001b[0m pairs \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# File path\u001b[39;00m\n\u001b[1;32m     20\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedingpairs.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m, in \u001b[0;36mgenerate_pairs\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(_)\n\u001b[1;32m     11\u001b[0m     n \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m])\n\u001b[0;32m---> 12\u001b[0m     a, b, imga, imgb \u001b[38;5;241m=\u001b[39m \u001b[43mbs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_two_random_embeddings_facenet\u001b[49m\u001b[43m(\u001b[49m\u001b[43msame_person\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     pairs\u001b[38;5;241m.\u001b[39mappend((a, b, imga, imgb,n))\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pairs\n",
      "File \u001b[0;32m~/Documents/uni/information security/Year 1/Semester 2/Block 2B/2IMS00/Seminar GIT/Seminar-PFFROCD/basics.py:135\u001b[0m, in \u001b[0;36mget_two_random_embeddings_facenet\u001b[0;34m(same_person)\u001b[0m\n\u001b[1;32m    133\u001b[0m     img2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlfw/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mperson2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrandom\u001b[38;5;241m.\u001b[39mchoice(os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlfw/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mperson2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# try to extract embeddings from both images\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     embedding1 \u001b[38;5;241m=\u001b[39m \u001b[43mget_embedding_facenet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     embedding2 \u001b[38;5;241m=\u001b[39m get_embedding_facenet(img2)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# failed to detect faces in images, try again\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# print(e)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/uni/information security/Year 1/Semester 2/Block 2B/2IMS00/Seminar GIT/Seminar-PFFROCD/basics.py:144\u001b[0m, in \u001b[0;36mget_embedding_facenet\u001b[0;34m(imagepath)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embedding_facenet\u001b[39m(imagepath):\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDeepFace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimagepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFacenet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/uni/information security/Year 1/Semester 2/Block 2B/2IMS00/Seminar GIT/Seminar-PFFROCD/env/lib/python3.12/site-packages/deepface/DeepFace.py:409\u001b[0m, in \u001b[0;36mrepresent\u001b[0;34m(img_path, model_name, enforce_detection, detector_backend, align, expand_percentage, normalization, anti_spoofing)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrepresent\u001b[39m(\n\u001b[1;32m    354\u001b[0m     img_path: Union[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray],\n\u001b[1;32m    355\u001b[0m     model_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVGG-Face\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m     anti_spoofing: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    362\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Represent facial images as multi-dimensional vector embeddings.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;124;03m            to 'skip', the confidence will be 0 and is nonsensical.\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrepresentation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manti_spoofing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/uni/information security/Year 1/Semester 2/Block 2B/2IMS00/Seminar GIT/Seminar-PFFROCD/env/lib/python3.12/site-packages/deepface/modules/representation.py:71\u001b[0m, in \u001b[0;36mrepresent\u001b[0;34m(img_path, model_name, enforce_detection, detector_backend, align, expand_percentage, normalization, anti_spoofing)\u001b[0m\n\u001b[1;32m     69\u001b[0m target_size \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39minput_shape\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detector_backend \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 71\u001b[0m     img_objs \u001b[38;5;241m=\u001b[39m \u001b[43mdetection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_faces\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrayscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manti_spoofing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# skip\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# Try load. If load error, will raise exception internal\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     img, _ \u001b[38;5;241m=\u001b[39m image_utils\u001b[38;5;241m.\u001b[39mload_image(img_path)\n",
      "File \u001b[0;32m~/Documents/uni/information security/Year 1/Semester 2/Block 2B/2IMS00/Seminar GIT/Seminar-PFFROCD/env/lib/python3.12/site-packages/deepface/modules/detection.py:76\u001b[0m, in \u001b[0;36mextract_faces\u001b[0;34m(img_path, detector_backend, enforce_detection, align, expand_percentage, grayscale, anti_spoofing)\u001b[0m\n\u001b[1;32m     73\u001b[0m resp_objs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# img might be path, base64 or numpy array. Convert it to numpy whatever it is.\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m img, img_name \u001b[38;5;241m=\u001b[39m \u001b[43mimage_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException while loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/uni/information security/Year 1/Semester 2/Block 2B/2IMS00/Seminar GIT/Seminar-PFFROCD/env/lib/python3.12/site-packages/deepface/commons/image_utils.py:102\u001b[0m, in \u001b[0;36mload_image\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img\u001b[38;5;241m.\u001b[39misascii() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput image must not have non-english characters - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 102\u001b[0m img_obj_bgr \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# img_obj_rgb = cv2.cvtColor(img_obj_bgr, cv2.COLOR_BGR2RGB)\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img_obj_bgr, img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### GENERATING THE GLOBAL PAIRS. \n",
    "### we only need to run this once and then we can have the file and use pairs as the list of embeddings \n",
    "### uncomment to use for first them, then use the next cell!\n",
    "\n",
    "#\n",
    "# Generate pairs globally\n",
    "def generate_pairs(m):\n",
    "    pairs = []\n",
    "    for _ in range(m):\n",
    "        print(_)\n",
    "        n = random.choice([True, False])\n",
    "        a, b, imga, imgb = bs.get_two_random_embeddings_facenet(same_person=n)\n",
    "        pairs.append((a, b, imga, imgb,n))\n",
    "    return pairs\n",
    "\n",
    "m = 1000\n",
    "pairs = generate_pairs(m)\n",
    "\n",
    "# File path\n",
    "file_path = 'embedingpairs.pkl'\n",
    "\n",
    "# Delete the file if it exists\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)\n",
    "\n",
    "# Save pairs to a new file\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(pairs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73af373-c771-4617-a869-09209e148aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embedingpairs.pkl', 'rb') as file:\n",
    "    pairs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae9dd79-9cb6-4b62-858d-cac9108b9d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_counters(counters):\n",
    "    for quant_func, results in counters.items():\n",
    "        print(f\"\\nQuantization Function: {quant_func}\")\n",
    "        for metric, count in results.items():\n",
    "            print(f\"{metric}: {count}\")\n",
    "\n",
    "def extract_results(counters):\n",
    "    methods = []\n",
    "    correct_sface_euc = []\n",
    "    incorrect_sface_euc = []\n",
    "    correct_sface_cos = []\n",
    "    incorrect_sface_cos = []\n",
    "    correct_facenet_euc = []\n",
    "    incorrect_facenet_euc = []\n",
    "    correct_facenet_cos = []\n",
    "    incorrect_facenet_cos = []\n",
    "\n",
    "    for method, counts in counters.items():\n",
    "        methods.append(method)\n",
    "        correct_sface_euc.append(counts['correct_tensor_sface'])\n",
    "        incorrect_sface_euc.append(counts['wrong_tensor_sface'])\n",
    "        correct_sface_cos.append(counts['correct_scalar_sface'])\n",
    "        incorrect_sface_cos.append(counts['wrong_scalar_sface'])\n",
    "        correct_facenet_euc.append(counts['correct_tensor_facenet'])\n",
    "        incorrect_facenet_euc.append(counts['wrong_tensor_facenet'])\n",
    "        correct_facenet_cos.append(counts['correct_scalar_facenet'])\n",
    "        incorrect_facenet_cos.append(counts['wrong_scalar_facenet'])\n",
    "    \n",
    "    return (methods, correct_sface_euc, incorrect_sface_euc, correct_sface_cos, incorrect_sface_cos, correct_facenet_euc, incorrect_facenet_euc, correct_facenet_cos, incorrect_facenet_cos)\n",
    "\n",
    "def visualize_results(methods, correct_sface_euc, incorrect_sface_euc, correct_sface_cos, incorrect_sface_cos, correct_facenet_euc, incorrect_facenet_euc, correct_facenet_cos, incorrect_facenet_cos):\n",
    "    n_methods = len(methods)\n",
    "    ind = np.arange(n_methods)\n",
    "    width = 0.1       \n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    bar1 = ax.bar(ind - width * 3.5, correct_sface_euc, width, label='Correct Euclidean (SFace)', color='skyblue')\n",
    "    bar2 = ax.bar(ind - width * 2.5, incorrect_sface_euc, width, label='Incorrect Euclidean (SFace)', color='palevioletred')\n",
    "    bar3 = ax.bar(ind - width * 1.5, correct_sface_cos, width, label='Correct Cosine (SFace)', color='orange')\n",
    "    bar4 = ax.bar(ind - width * 0.5, incorrect_sface_cos, width, label='Incorrect Cosine (SFace)', color='purple')\n",
    "    bar5 = ax.bar(ind + width * 0.5, correct_facenet_euc, width, label='Correct Euclidean (Facenet)', color='lightgreen')\n",
    "    bar6 = ax.bar(ind + width * 1.5, incorrect_facenet_euc, width, label='Incorrect Euclidean (Facenet)', color='blueviolet')\n",
    "    bar7 = ax.bar(ind + width * 2.5, correct_facenet_cos, width, label='Correct Cosine (Facenet)', color='lightcoral')\n",
    "    bar8 = ax.bar(ind + width * 3.5, incorrect_facenet_cos, width, label='Incorrect Cosine (Facenet)', color='gold')\n",
    "\n",
    "    for bars in [bar1, bar2, bar3, bar4, bar5, bar6, bar7, bar8]:\n",
    "        for i, bar in enumerate(bars):\n",
    "            ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.5, str(int(bar.get_height())), ha='center', va='bottom')\n",
    "\n",
    "    ax.set_xlabel('Quantisation Methods')\n",
    "    ax.set_ylabel('Values')\n",
    "    ax.set_title('Accuracy Comparison of Different Quantisation Methods using SFace and Facenet (Euclidean Distance and Cosine Similarity)')\n",
    "    ax.set_xticks(ind)\n",
    "    ax.set_xticklabels(methods, rotation=45, ha='right')\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(1.4, 1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Running the comparison functions\n",
    "counters_euc = ac.compare_accuracies_euc(pairs)\n",
    "counters_cos = ac.compare_accuracies_cos(pairs)\n",
    "\n",
    "# Print the counters for each function\n",
    "print(\"Euclidean Distance Results:\")\n",
    "print_counters(counters_euc)\n",
    "\n",
    "print(\"Cosine Similarity Results:\")\n",
    "print_counters(counters_cos)\n",
    "\n",
    "# Extract results for visualization\n",
    "(methods, correct_sface_euc, incorrect_sface_euc, correct_sface_cos, incorrect_sface_cos, correct_facenet_euc, incorrect_facenet_euc, correct_facenet_cos, incorrect_facenet_cos) = extract_results(counters_euc)\n",
    "\n",
    "# Visualize the results\n",
    "visualize_results(methods, correct_sface_euc, incorrect_sface_euc, correct_sface_cos, incorrect_sface_cos, correct_facenet_euc, incorrect_facenet_euc, correct_facenet_cos, incorrect_facenet_cos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dfd6b5-7d11-4b2c-8075-05fbbea36e7e",
   "metadata": {},
   "source": [
    "below will be the functions to compare the execution time of (Facenet, SFace) x (Euclidean, Cosine) X (no quantisation, Tensorflow, scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555b6b93-8603-4e8f-a79c-9fa3b38fa0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your experiments\n",
    "experiments = [\n",
    "    {\"n\": 1000, \"get_embedding_func\": bs.get_embedding_facenet, \"quantize_func\": None, \"distance_func\": bs.get_cos_dist_numpy, \"quantize\": False},\n",
    "    {\"n\": 1000, \"get_embedding_func\": bs.get_embedding_facenet, \"quantize_func\": None, \"distance_func\": bs.euclidean_distance, \"quantize\": False},\n",
    "    {\"n\": 1000, \"get_embedding_func\": bs.get_embedding_facenet, \"quantize_func\": qt.scalar_quantisation_percentile, \"distance_func\": bs.get_cos_dist_numpy, \"quantize\": True},\n",
    "    {\"n\": 1000, \"get_embedding_func\": bs.get_embedding_facenet, \"quantize_func\": qt.scalar_quantisation_percentile, \"distance_func\": bs.euclidean_distance, \"quantize\": True},\n",
    "    {\"n\": 1000, \"get_embedding_func\": bs.get_embedding_facenet, \"quantize_func\": qt.quantize_tensor, \"distance_func\": bs.get_cos_dist_numpy, \"quantize\": True},\n",
    "    {\"n\": 1000, \"get_embedding_func\": bs.get_embedding_facenet, \"quantize_func\": qt.quantize_tensor, \"distance_func\": bs.euclidean_distance, \"quantize\": True},\n",
    "    {\"n\": 1000, \"get_embedding_func\": bs.get_embedding, \"quantize_func\": None, \"distance_func\": bs.get_cos_dist_numpy, \"quantize\": False},\n",
    "    {\"n\": 1000, \"get_embedding_func\": bs.get_embedding, \"quantize_func\": None, \"distance_func\": bs.euclidean_distance, \"quantize\": False},\n",
    "    {\"n\": 1000, \"get_embedding_func\": bs.get_embedding, \"quantize_func\": qt.scalar_quantisation_percentile, \"distance_func\": bs.get_cos_dist_numpy, \"quantize\": True},\n",
    "    {\"n\": 1000, \"get_embedding_func\": bs.get_embedding, \"quantize_func\": qt.scalar_quantisation_percentile, \"distance_func\": bs.euclidean_distance, \"quantize\": True},\n",
    "    {\"n\": 1000, \"get_embedding_func\": bs.get_embedding, \"quantize_func\": qt.quantize_tensor, \"distance_func\": bs.get_cos_dist_numpy, \"quantize\": True},\n",
    "    {\"n\": 1000, \"get_embedding_func\": bs.get_embedding, \"quantize_func\": qt.quantize_tensor, \"distance_func\": bs.euclidean_distance, \"quantize\": True},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5550b485-4921-417d-a6d3-6c462505edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(n, get_embedding_func, quantize_func, distance_func, quantize=False):\n",
    "    execution_times = []\n",
    "\n",
    "    for _ in range(n):\n",
    "        a, b, imga, imgb,n = pairs[_]\n",
    "        start_time = time.time()\n",
    "        a = get_embedding_func(imga)\n",
    "        b = get_embedding_func(imgb)\n",
    "        \n",
    "        if quantize:\n",
    "            a = quantize_func(a)\n",
    "            b = quantize_func(b)\n",
    "        \n",
    "        if distance_func == bs.get_cos_dist_numpy:\n",
    "            a = a / np.linalg.norm(a)\n",
    "            b = b / np.linalg.norm(b)\n",
    "        \n",
    "        distance_func(a, b)\n",
    "        end_time = time.time()\n",
    "\n",
    "        execution_time = end_time - start_time\n",
    "        execution_times.append(execution_time)\n",
    "    \n",
    "    return execution_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ee4acf-7cc2-4333-956e-d11348761dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all experiments\n",
    "results = {}\n",
    "for i, experiment in enumerate(experiments):\n",
    "    key = f\"experiment_{i+1}\"\n",
    "    results[key] = run_experiment(**experiment)\n",
    "    print(f\"{key} completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ec8d00-d96f-42e1-80e0-66eefa607dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary with experiment names for readability\n",
    "experiment_names = {\n",
    "    \"experiment_1\": \"avg_execution_times_no_quantisation_facenet_cos\",\n",
    "    \"experiment_2\": \"avg_execution_times_no_quantisation_facenet_ed\",\n",
    "    \"experiment_3\": \"avg_execution_times_scalar_quantisation_facenet_cos\",\n",
    "    \"experiment_4\": \"avg_execution_times_scalar_quantisation_facenet_ed\",\n",
    "    \"experiment_5\": \"avg_execution_times_tensorflow_quantisation_facenet_cos\",\n",
    "    \"experiment_6\": \"avg_execution_times_tensorflow_quantisation_facenet_ed\",\n",
    "    \"experiment_7\": \"avg_execution_times_no_quantisation_sface_cos\",\n",
    "    \"experiment_8\": \"avg_execution_times_no_quantisation_sface_ed\",\n",
    "    \"experiment_9\": \"avg_execution_times_scalar_quantisation_sface_cos\",\n",
    "    \"experiment_10\": \"avg_execution_times_scalar_quantisation_sface_ed\",\n",
    "    \"experiment_11\": \"avg_execution_times_tensorflow_quantisation_sface_cos\",\n",
    "    \"experiment_12\": \"avg_execution_times_tensorflow_quantisation_sface_ed\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6051591c-1fac-4c71-a529-5c9c0bed5f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print the average execution times\n",
    "for key, name in experiment_names.items():\n",
    "    avg_time = statistics.mean(results[key])\n",
    "    print(f\"{name} = {avg_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1a2410-8b89-4cbd-bc4d-4e94810c69fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define quantization functions\n",
    "quantization_functions = {\n",
    "    \"scalar_quantisation_max\": qt.scalar_quantisation_max,\n",
    "    \"scalar_quantisation_percentile\": qt.scalar_quantisation_percentile,\n",
    "    \"scalar_quantisation_tensorrt\": qt.scalar_quantisation_tensorrt\n",
    "}\n",
    "\n",
    "# Define your experiments\n",
    "experiments = []\n",
    "\n",
    "embedding_functions = [bs.get_embedding_facenet, bs.get_embedding]\n",
    "distance_functions = [bs.get_cos_dist_numpy, bs.euclidean_distance]\n",
    "\n",
    "# Add experiments for no quantization\n",
    "for get_embedding_func in embedding_functions:\n",
    "    for distance_func in distance_functions:\n",
    "        experiments.append({\n",
    "            \"n\": 1000,\n",
    "            \"get_embedding_func\": get_embedding_func,\n",
    "            \"quantize_func\": None,\n",
    "            \"distance_func\": distance_func,\n",
    "            \"quantize\": False\n",
    "        })\n",
    "\n",
    "# Add experiments for tensor quantization\n",
    "for get_embedding_func in embedding_functions:\n",
    "    for distance_func in distance_functions:\n",
    "        experiments.append({\n",
    "            \"n\": 1000,\n",
    "            \"get_embedding_func\": get_embedding_func,\n",
    "            \"quantize_func\": qt.quantize_tensor,\n",
    "            \"distance_func\": distance_func,\n",
    "            \"quantize\": True\n",
    "        })\n",
    "\n",
    "# Add experiments for each scalar quantization method\n",
    "for get_embedding_func in embedding_functions:\n",
    "    for distance_func in distance_functions:\n",
    "        for name, quant_func in quantization_functions.items():\n",
    "            experiments.append({\n",
    "                \"n\": 1000,\n",
    "                \"get_embedding_func\": get_embedding_func,\n",
    "                \"quantize_func\": quant_func,\n",
    "                \"distance_func\": distance_func,\n",
    "                \"quantize\": True\n",
    "            })\n",
    "\n",
    "def run_experiment(n, get_embedding_func, quantize_func, distance_func, quantize=False):\n",
    "    execution_times = []\n",
    "\n",
    "    for _ in range(n):\n",
    "        a, b, imga, imgb, n = pairs[_]\n",
    "        start_time = time.time()\n",
    "        a = get_embedding_func(imga)\n",
    "        b = get_embedding_func(imgb)\n",
    "        \n",
    "        if quantize:\n",
    "            a = quantize_func(a)\n",
    "            b = quantize_func(b)\n",
    "        \n",
    "        if distance_func == bs.get_cos_dist_numpy:\n",
    "            a = a / np.linalg.norm(a)\n",
    "            b = b / np.linalg.norm(b)\n",
    "        \n",
    "        distance_func(a, b)\n",
    "        end_time = time.time()\n",
    "\n",
    "        execution_time = end_time - start_time\n",
    "        execution_times.append(execution_time)\n",
    "    \n",
    "    return execution_times\n",
    "\n",
    "# Run all experiments\n",
    "results = {}\n",
    "for i, experiment in enumerate(experiments):\n",
    "    key = f\"experiment_{i+1}\"\n",
    "    results[key] = run_experiment(**experiment)\n",
    "    print(f\"{key} completed\")\n",
    "\n",
    "# Define a dictionary with experiment names for readability\n",
    "experiment_names = {\n",
    "    \"experiment_1\": \"avg_execution_times_no_quantisation_facenet_cos\",\n",
    "    \"experiment_2\": \"avg_execution_times_no_quantisation_facenet_ed\",\n",
    "    \"experiment_3\": \"avg_execution_times_no_quantisation_sface_cos\",\n",
    "    \"experiment_4\": \"avg_execution_times_no_quantisation_sface_ed\",\n",
    "    \"experiment_5\": \"avg_execution_times_tensor_quantisation_facenet_cos\",\n",
    "    \"experiment_6\": \"avg_execution_times_tensor_quantisation_facenet_ed\",\n",
    "    \"experiment_7\": \"avg_execution_times_tensor_quantisation_sface_cos\",\n",
    "    \"experiment_8\": \"avg_execution_times_tensor_quantisation_sface_ed\",\n",
    "    \"experiment_9\": \"avg_execution_times_scalar_quantisation_max_facenet_cos\",\n",
    "    \"experiment_10\": \"avg_execution_times_scalar_quantisation_max_facenet_ed\",\n",
    "    \"experiment_11\": \"avg_execution_times_scalar_quantisation_max_sface_cos\",\n",
    "    \"experiment_12\": \"avg_execution_times_scalar_quantisation_max_sface_ed\",\n",
    "    \"experiment_13\": \"avg_execution_times_scalar_quantisation_percentile_facenet_cos\",\n",
    "    \"experiment_14\": \"avg_execution_times_scalar_quantisation_percentile_facenet_ed\",\n",
    "    \"experiment_15\": \"avg_execution_times_scalar_quantisation_percentile_sface_cos\",\n",
    "    \"experiment_16\": \"avg_execution_times_scalar_quantisation_percentile_sface_ed\",\n",
    "    \"experiment_17\": \"avg_execution_times_scalar_quantisation_tensorrt_facenet_cos\",\n",
    "    \"experiment_18\": \"avg_execution_times_scalar_quantisation_tensorrt_facenet_ed\",\n",
    "    \"experiment_19\": \"avg_execution_times_scalar_quantisation_tensorrt_sface_cos\",\n",
    "    \"experiment_20\": \"avg_execution_times_scalar_quantisation_tensorrt_sface_ed\"\n",
    "}\n",
    "\n",
    "# Calculate and print the average execution times\n",
    "for key, name in experiment_names.items():\n",
    "    avg_time = statistics.mean(results[key])\n",
    "    print(f\"{name} = {avg_time}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
