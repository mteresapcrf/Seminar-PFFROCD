{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55bca6d-cb6b-4ec1-bbad-9448b147967c",
   "metadata": {},
   "source": [
    "In this notebook different quantisation methods and distance metrics for Facial Recognition will be compared both on accuracy and execution time. \n",
    "\n",
    "The Quantisation methods include:\n",
    "- Scalar Quantisation\n",
    "- TensorFlow Quantisation\n",
    "\n",
    "The distance metrics include:\n",
    "- Cosine Similarity\n",
    "- Euclidean Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a699d2ca-b77e-4f7d-8ff3-d0cedef542fd",
   "metadata": {},
   "source": [
    "Below are the necassary import to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37ab3d98-13d1-46ec-b5d4-fda1f58c7092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # suppress tensorflow warnings https://stackoverflow.com/a/40871012\n",
    "from deepface import DeepFace\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from decimal import Decimal # for proper rounding\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import struct\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import statistics\n",
    "import accuracy as ac\n",
    "import pickle\n",
    "import quantisations as qt\n",
    "import basics as bs\n",
    "\n",
    "\n",
    "# CONSTANTS\n",
    "EXECUTABLE_PATH = \"ABY/build/bin\"\n",
    "INPUT_FILE_NAME = \"input_vecs.txt\"\n",
    "EXECUTABLE_NAME_SCENARIO = 'cos_dist_copy'\n",
    "CMD_SCENARIO = f\"./{EXECUTABLE_NAME_SCENARIO} -r 1 -f {INPUT_FILE_NAME} & (./{EXECUTABLE_NAME_SCENARIO} -r 0 -f {INPUT_FILE_NAME} 2>&1 > /dev/null)\"\n",
    "\n",
    "# random number generator\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3253443-22b2-4600-8762-01d70057a928",
   "metadata": {},
   "source": [
    "Here we test if quantisation works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c43bae1-cad9-4589-af0b-b55ba7470d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size before scalar quantisation: 1080 , size after scalar quantisation: 240\n",
      "size before tensor quantisation: 1080 , size after tensor quantisation: 240\n",
      "the type of the elements in the scalar quantisation is: <class 'numpy.int8'> in the non quantised embedding it was: <class 'float'>\n",
      "the type of the elements in the tensor quantisation is: <class 'numpy.int8'> in the non quantised embedding it was: <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "embedding1 = bs.get_embedding(\"lfw/George_W_Bush/George_W_Bush_0001.jpg\")\n",
    "embedding2 = bs.get_embedding(\"lfw/George_W_Bush/George_W_Bush_0002.jpg\")\n",
    "bs.get_cos_dist_numpy(embedding1, embedding2)\n",
    "# print(embedding1)\n",
    "embedding1_quant=qt.scalar_quantisation_percentile(embedding1)\n",
    "embedding2_quant=qt.quantize_tensor(embedding2)\n",
    "print(\"size before scalar quantisation:\" ,sys.getsizeof(embedding1), \", size after scalar quantisation:\",sys.getsizeof(embedding1_quant)) \n",
    "print(\"size before tensor quantisation:\", sys.getsizeof(embedding2), \", size after tensor quantisation:\",sys.getsizeof(embedding2_quant)) \n",
    "print(\"the type of the elements in the scalar quantisation is:\", type(embedding1_quant[0]), \"in the non quantised embedding it was:\",type(embedding1[0]))\n",
    "print(\"the type of the elements in the tensor quantisation is:\", type(embedding2_quant[0]), \"in the non quantised embedding it was:\",type(embedding2[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316b1680-eeee-43a6-9a23-98021e2251ec",
   "metadata": {},
   "source": [
    "Below are two functions to compare Facenet and Sface accuracy. One for Euclidean Distance and one for Cosine Similarity. The code to create a visual representation for this comparison is also included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956e56f4-0543-436e-a677-2edc2bd4c78a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n"
     ]
    }
   ],
   "source": [
    "### GENERATING THE GLOBAL PAIRS. \n",
    "### we only need to run this once and then we can have the file and use pairs as the list of embeddings \n",
    "### uncomment to use for first them, then use the next cell!\n",
    "### since we are using the github you already have the file so just use the next cell!!\n",
    "\n",
    "\n",
    "# Generate pairs globally\n",
    "def generate_pairs(m):\n",
    "    pairs = []\n",
    "    for _ in range(m):\n",
    "        print(_)\n",
    "        n = random.choice([True, False])\n",
    "        a, b, imga, imgb = bs.get_two_random_embeddings_facenet(same_person=n)\n",
    "        pairs.append((a, b, imga, imgb))\n",
    "    return pairs\n",
    "\n",
    "m = 1000\n",
    "pairs = generate_pairs(m)\n",
    "\n",
    "\n",
    "# Save pairs to a file\n",
    "with open('pairs.pkl', 'wb') as file:\n",
    "    pickle.dump(pairs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73af373-c771-4617-a869-09209e148aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pairs.pkl', 'rb') as file:\n",
    "    pairs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a95d70-f3c8-4cac-9ca9-fb3f9d11478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Euclidean distance\n",
    "correct_f_euc, incorrect_f_euc, correct_s_euc, incorrect_s_euc = ac.compare_accuracies_euc(pairs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac285f1-f5b7-454b-9573-5bba8dacc098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use Euclidean distance\n",
    "correct_f_cos, incorrect_f_cos, correct_s_cos, incorrect_s_cos = ac.compare_accuracies_cos(pairs, m)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301c4fee-a49e-4522-ad9e-64a2671b195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"facenet euclidean - correct :\", correct_f_euc, \"incorrect:\", incorrect_f_euc)\n",
    "print(\"sface euclidean - correct:\", correct_s_euc, \"incorrect:\", incorrect_s_euc)\n",
    "\n",
    "print(\"facenet cosine - correct :\", correct_f_cos, \"incorrect:\", incorrect_f_euc)\n",
    "print(\"sface cosine - correct:\", correct_s_cos, \"incorrect:\", incorrect_s_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac21fc1b-be03-4fca-a6e5-6f8d422550c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualisation for ED\n",
    "\n",
    "# Data\n",
    "methods = ['No quantisation', 'Scalar Quantisation (8 bits)', 'Tensorflow Quantisation (8 bits)']\n",
    "correct_sface_euc = correct_s_euc\n",
    "incorrect_sface_cos = incorrect_s_euc\n",
    "correct_sface_cos = correct_s_cos\n",
    "incorrect_sface_cos = incorrect_s_cos\n",
    "correct_facenet_euc = correct_f_euc\n",
    "incorrect_facenet_euc = incorrect_f_euc\n",
    "correct_facenet_cos = correct_f_cos\n",
    "incorrect_facenet_cos = incorrect_f_cos\n",
    "\n",
    "# Number of methods\n",
    "n_methods = len(methods)\n",
    "\n",
    "# Position of bars on X axis\n",
    "ind = np.arange(n_methods)\n",
    "\n",
    "# Width of a bar \n",
    "width = 0.2       \n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Bar plots for SFace\n",
    "bar1 = ax.bar(ind - width * 1.5, correct_sface_euc, width, label='Correct Euclidean (SFace)', color='skyblue')\n",
    "bar2 = ax.bar(ind - width * 0.5, incorrect_sface_euc, width, label='Incorrect Euclidean (SFace)', color='palevioletred')\n",
    "\n",
    "bar3 = ax.bar(ind - width * 1.5, correct_sface_cos, width, label='Correct Cosine(SFace)', color='orange')\n",
    "bar4 = ax.bar(ind - width * 0.5, incorrect_sface_cos, width, label='Incorrect Cosine (SFace)', color='lightpurple')\n",
    "\n",
    "\n",
    "# Bar plots for Facenet\n",
    "bar5 = ax.bar(ind + width * 0.5, correct_facenet_euc, width, label='Correct Euclidean (Facenet)', color='lightgreen')\n",
    "bar6 = ax.bar(ind + width * 1.5, incorrect_facenet_euc, width, label='Incorrect Euclidean (Facenet)', color='blueviolet')\n",
    "\n",
    "bar7 = ax.bar(ind + width * 0.5, correct_facenet_cos, width, label='Correct Cosine (Facenet)', color='lightgreen')\n",
    "bar8 = ax.bar(ind + width * 1.5, incorrect_facenet_cos, width, label='Incorrect Consine(Facenet)', color='blueviolet')\n",
    "\n",
    "# Adding text labels for all bars\n",
    "for bars in [bar1, bar2, bar3, bar4, bar5, bar6, bar7, bar8]:\n",
    "    for i, bar in enumerate(bars):\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.5, str(int(bar.get_height())), ha='center', va='bottom')\n",
    "\n",
    "# Labels, title and axes ticks\n",
    "ax.set_xlabel('Quantisation Methods')\n",
    "ax.set_ylabel('Values')\n",
    "ax.set_title('Accuracy Comparison of Different Quantisation Methods using SFace and Facenet (Euclidean Distance and Cosine Similarity)')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(methods, rotation=45, ha='right')\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1))\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dfd6b5-7d11-4b2c-8075-05fbbea36e7e",
   "metadata": {},
   "source": [
    "below will be the functions to compare the execution time of (Facenet, SFace) x (Euclidean, Cosine) X (no quantisation, Tensorflow, scalar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c3fb4b-25da-44ca-8562-54b0869d6993",
   "metadata": {},
   "source": [
    "Below is the code to draw to figures visualising the accuracy, one for facenet and one for sface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555b6b93-8603-4e8f-a79c-9fa3b38fa0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your experiments\n",
    "experiments = [\n",
    "    {\"n\": 1000, \"embedding_func\": get_embedding_facenet, \"quantize_func\": None, \"distance_func\": get_cos_dist_numpy, \"quantize\": False},\n",
    "    {\"n\": 1000, \"embedding_func\": get_embedding_facenet, \"quantize_func\": None, \"distance_func\": euclidean_distance, \"quantize\": False},\n",
    "    {\"n\": 1000, \"embedding_func\": get_embedding_facenet, \"quantize_func\": scalar_quantisation_percentile, \"distance_func\": get_cos_dist_numpy, \"quantize\": True},\n",
    "    {\"n\": 1000, \"embedding_func\": get_embedding_facenet, \"quantize_func\": scalar_quantisation_percentile, \"distance_func\": euclidean_distance, \"quantize\": True},\n",
    "    {\"n\": 1000, \"embedding_func\": get_embedding_facenet, \"quantize_func\": quantize_tensor, \"distance_func\": get_cos_dist_numpy, \"quantize\": True},\n",
    "    {\"n\": 1000, \"embedding_func\": get_embedding_facenet, \"quantize_func\": quantize_tensor, \"distance_func\": euclidean_distance, \"quantize\": True},\n",
    "    {\"n\": 1000, \"embedding_func\": get_embedding, \"quantize_func\": None, \"distance_func\": get_cos_dist_numpy, \"quantize\": False},\n",
    "    {\"n\": 1000, \"embedding_func\": get_embedding, \"quantize_func\": None, \"distance_func\": euclidean_distance, \"quantize\": False},\n",
    "    {\"n\": 1000, \"embedding_func\": get_embedding, \"quantize_func\": scalar_quantisation_percentile, \"distance_func\": get_cos_dist_numpy, \"quantize\": True},\n",
    "    {\"n\": 1000, \"embedding_func\": get_embedding, \"quantize_func\": scalar_quantisation_percentile, \"distance_func\": euclidean_distance, \"quantize\": True},\n",
    "    {\"n\": 1000, \"embedding_func\": get_embedding, \"quantize_func\": quantize_tensor, \"distance_func\": get_cos_dist_numpy, \"quantize\": True},\n",
    "    {\"n\": 1000, \"embedding_func\": get_embedding, \"quantize_func\": quantize_tensor, \"distance_func\": euclidean_distance, \"quantize\": True},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5550b485-4921-417d-a6d3-6c462505edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(n, get_embedding_func, quantize_func, distance_func, quantize=False):\n",
    "    execution_times = []\n",
    "\n",
    "    for _ in range(n):\n",
    "        print(_)\n",
    "        same_person = random.choice([True, False])\n",
    "        a, b, imga, imgb = get_two_random_embeddings(same_person=same_person)\n",
    "        start_time = time.time()\n",
    "        a = get_embedding_func(imga)\n",
    "        b = get_embedding_func(imgb)\n",
    "        \n",
    "        if quantize:\n",
    "            a = quantize_func(a)\n",
    "            b = quantize_func(b)\n",
    "        \n",
    "        if distance_func == get_cos_dist_numpy:\n",
    "            a = a / np.linalg.norm(a)\n",
    "            b = b / np.linalg.norm(b)\n",
    "        \n",
    "        distance_func(a, b)\n",
    "        end_time = time.time()\n",
    "\n",
    "        execution_time = end_time - start_time\n",
    "        execution_times.append(execution_time)\n",
    "    \n",
    "    return execution_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ee4acf-7cc2-4333-956e-d11348761dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all experiments\n",
    "results = {}\n",
    "for i, experiment in enumerate(experiments):\n",
    "    key = f\"experiment_{i+1}\"\n",
    "    results[key] = run_experiment(**experiment)\n",
    "    print(f\"{key} completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ec8d00-d96f-42e1-80e0-66eefa607dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary with experiment names for readability\n",
    "experiment_names = {\n",
    "    \"experiment_1\": \"avg_execution_times_no_quantisation_facenet_cos\",\n",
    "    \"experiment_2\": \"avg_execution_times_no_quantisation_facenet_ed\",\n",
    "    \"experiment_3\": \"avg_execution_times_scalar_quantisation_facenet_cos\",\n",
    "    \"experiment_4\": \"avg_execution_times_scalar_quantisation_facenet_ed\",\n",
    "    \"experiment_5\": \"avg_execution_times_tensorflow_quantisation_facenet_cos\",\n",
    "    \"experiment_6\": \"avg_execution_times_tensorflow_quantisation_facenet_ed\",\n",
    "    \"experiment_7\": \"avg_execution_times_no_quantisation_sface_cos\",\n",
    "    \"experiment_8\": \"avg_execution_times_no_quantisation_sface_ed\",\n",
    "    \"experiment_9\": \"avg_execution_times_scalar_quantisation_sface_cos\",\n",
    "    \"experiment_10\": \"avg_execution_times_scalar_quantisation_sface_ed\",\n",
    "    \"experiment_11\": \"avg_execution_times_tensorflow_quantisation_sface_cos\",\n",
    "    \"experiment_12\": \"avg_execution_times_tensorflow_quantisation_sface_ed\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6051591c-1fac-4c71-a529-5c9c0bed5f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print the average execution times\n",
    "for key, name in experiment_names.items():\n",
    "    avg_time = statistics.mean(results[key])\n",
    "    print(f\"{name} = {avg_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
