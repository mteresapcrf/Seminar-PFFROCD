{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55bca6d-cb6b-4ec1-bbad-9448b147967c",
   "metadata": {},
   "source": [
    "In this notebook different quantisation methods and distance metrics for Facial Recognition will be compared both on accuracy and execution time. \n",
    "\n",
    "The Quantisation methods include:\n",
    "- Scalar Quantisation\n",
    "- TensorFlow Quantisation\n",
    "\n",
    "The distance metrics include:\n",
    "- Cosine Similarity\n",
    "- Euclidean Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a699d2ca-b77e-4f7d-8ff3-d0cedef542fd",
   "metadata": {},
   "source": [
    "Below are the necassary import to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37ab3d98-13d1-46ec-b5d4-fda1f58c7092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # suppress tensorflow warnings https://stackoverflow.com/a/40871012\n",
    "from deepface import DeepFace\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from decimal import Decimal # for proper rounding\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import struct\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import statistics\n",
    "import accuracy as ac\n",
    "import pickle\n",
    "import quantisations as qt\n",
    "import basics as bs\n",
    "\n",
    "\n",
    "# CONSTANTS\n",
    "EXECUTABLE_PATH = \"ABY/build/bin\"\n",
    "INPUT_FILE_NAME = \"input_vecs.txt\"\n",
    "EXECUTABLE_NAME_SCENARIO = 'cos_dist_copy'\n",
    "CMD_SCENARIO = f\"./{EXECUTABLE_NAME_SCENARIO} -r 1 -f {INPUT_FILE_NAME} & (./{EXECUTABLE_NAME_SCENARIO} -r 0 -f {INPUT_FILE_NAME} 2>&1 > /dev/null)\"\n",
    "\n",
    "# random number generator\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3253443-22b2-4600-8762-01d70057a928",
   "metadata": {},
   "source": [
    "Here we test if quantisation works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c43bae1-cad9-4589-af0b-b55ba7470d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size before scalar quantisation: 1080 , size after scalar quantisation: 240\n",
      "size before tensor quantisation: 1080 , size after tensor quantisation: 240\n",
      "the type of the elements in the scalar quantisation is: <class 'numpy.int8'> in the non quantised embedding it was: <class 'float'>\n",
      "the type of the elements in the tensor quantisation is: <class 'numpy.int8'> in the non quantised embedding it was: <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "embedding1 = bs.get_embedding(\"lfw/George_W_Bush/George_W_Bush_0001.jpg\")\n",
    "embedding2 = bs.get_embedding(\"lfw/George_W_Bush/George_W_Bush_0002.jpg\")\n",
    "bs.get_cos_dist_numpy(embedding1, embedding2)\n",
    "# print(embedding1)\n",
    "embedding1_quant=qt.scalar_quantisation_percentile(embedding1)\n",
    "embedding2_quant=qt.quantize_tensor(embedding2)\n",
    "print(\"size before scalar quantisation:\" ,sys.getsizeof(embedding1), \", size after scalar quantisation:\",sys.getsizeof(embedding1_quant)) \n",
    "print(\"size before tensor quantisation:\", sys.getsizeof(embedding2), \", size after tensor quantisation:\",sys.getsizeof(embedding2_quant)) \n",
    "print(\"the type of the elements in the scalar quantisation is:\", type(embedding1_quant[0]), \"in the non quantised embedding it was:\",type(embedding1[0]))\n",
    "print(\"the type of the elements in the tensor quantisation is:\", type(embedding2_quant[0]), \"in the non quantised embedding it was:\",type(embedding2[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316b1680-eeee-43a6-9a23-98021e2251ec",
   "metadata": {},
   "source": [
    "Below are two functions to compare Facenet and Sface accuracy. One for Euclidean Distance and one for Cosine Similarity. The code to create a visual representation for this comparison is also included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956e56f4-0543-436e-a677-2edc2bd4c78a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "### GENERATING THE GLOBAL PAIRS. \n",
    "### we only need to run this once and then we can have the file and use pairs as the list of embeddings \n",
    "### uncomment to use for first them, then use the next cell!\n",
    "\n",
    "#\n",
    "# Generate pairs globally\n",
    "def generate_pairs(m):\n",
    "    pairs = []\n",
    "    for _ in range(m):\n",
    "        print(_)\n",
    "        n = random.choice([True, False])\n",
    "        a, b, imga, imgb = bs.get_two_random_embeddings_facenet(same_person=n)\n",
    "        pairs.append((a, b, imga, imgb,n))\n",
    "    return pairs\n",
    "\n",
    "m = 1000\n",
    "pairs = generate_pairs(m)\n",
    "\n",
    "# File path\n",
    "file_path = 'embedingpairs.pkl'\n",
    "\n",
    "# Delete the file if it exists\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)\n",
    "\n",
    "# Save pairs to a new file\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(pairs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73af373-c771-4617-a869-09209e148aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embedingpairs.pkl', 'rb') as file:\n",
    "    pairs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae9dd79-9cb6-4b62-858d-cac9108b9d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_counters(counters):\n",
    "    for quant_func, results in counters.items():\n",
    "        print(f\"\\nQuantization Function: {quant_func}\")\n",
    "        for metric, count in results.items():\n",
    "            print(f\"{metric}: {count}\")\n",
    "\n",
    "def extract_results(counters):\n",
    "    methods = []\n",
    "    correct_sface_euc = []\n",
    "    incorrect_sface_euc = []\n",
    "    correct_sface_cos = []\n",
    "    incorrect_sface_cos = []\n",
    "    correct_facenet_euc = []\n",
    "    incorrect_facenet_euc = []\n",
    "    correct_facenet_cos = []\n",
    "    incorrect_facenet_cos = []\n",
    "\n",
    "    for method, counts in counters.items():\n",
    "        methods.append(method)\n",
    "        correct_sface_euc.append(counts['correct_tensor_sface'])\n",
    "        incorrect_sface_euc.append(counts['wrong_tensor_sface'])\n",
    "        correct_sface_cos.append(counts['correct_scalar_sface'])\n",
    "        incorrect_sface_cos.append(counts['wrong_scalar_sface'])\n",
    "        correct_facenet_euc.append(counts['correct_tensor_facenet'])\n",
    "        incorrect_facenet_euc.append(counts['wrong_tensor_facenet'])\n",
    "        correct_facenet_cos.append(counts['correct_scalar_facenet'])\n",
    "        incorrect_facenet_cos.append(counts['wrong_scalar_facenet'])\n",
    "    \n",
    "    return (methods, correct_sface_euc, incorrect_sface_euc, correct_sface_cos, incorrect_sface_cos, correct_facenet_euc, incorrect_facenet_euc, correct_facenet_cos, incorrect_facenet_cos)\n",
    "\n",
    "def visualize_results(methods, correct_sface_euc, incorrect_sface_euc, correct_sface_cos, incorrect_sface_cos, correct_facenet_euc, incorrect_facenet_euc, correct_facenet_cos, incorrect_facenet_cos):\n",
    "    n_methods = len(methods)\n",
    "    ind = np.arange(n_methods)\n",
    "    width = 0.1       \n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    bar1 = ax.bar(ind - width * 3.5, correct_sface_euc, width, label='Correct Euclidean (SFace)', color='skyblue')\n",
    "    bar2 = ax.bar(ind - width * 2.5, incorrect_sface_euc, width, label='Incorrect Euclidean (SFace)', color='palevioletred')\n",
    "    bar3 = ax.bar(ind - width * 1.5, correct_sface_cos, width, label='Correct Cosine (SFace)', color='orange')\n",
    "    bar4 = ax.bar(ind - width * 0.5, incorrect_sface_cos, width, label='Incorrect Cosine (SFace)', color='purple')\n",
    "    bar5 = ax.bar(ind + width * 0.5, correct_facenet_euc, width, label='Correct Euclidean (Facenet)', color='lightgreen')\n",
    "    bar6 = ax.bar(ind + width * 1.5, incorrect_facenet_euc, width, label='Incorrect Euclidean (Facenet)', color='blueviolet')\n",
    "    bar7 = ax.bar(ind + width * 2.5, correct_facenet_cos, width, label='Correct Cosine (Facenet)', color='lightcoral')\n",
    "    bar8 = ax.bar(ind + width * 3.5, incorrect_facenet_cos, width, label='Incorrect Cosine (Facenet)', color='gold')\n",
    "\n",
    "    for bars in [bar1, bar2, bar3, bar4, bar5, bar6, bar7, bar8]:\n",
    "        for i, bar in enumerate(bars):\n",
    "            ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.5, str(int(bar.get_height())), ha='center', va='bottom')\n",
    "\n",
    "    ax.set_xlabel('Quantisation Methods')\n",
    "    ax.set_ylabel('Values')\n",
    "    ax.set_title('Accuracy Comparison of Different Quantisation Methods using SFace and Facenet (Euclidean Distance and Cosine Similarity)')\n",
    "    ax.set_xticks(ind)\n",
    "    ax.set_xticklabels(methods, rotation=45, ha='right')\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(1.4, 1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Running the comparison functions\n",
    "counters_euc = ac.compare_accuracies_euc(pairs)\n",
    "counters_cos = ac.compare_accuracies_cos(pairs)\n",
    "\n",
    "# Print the counters for each function\n",
    "print(\"Euclidean Distance Results:\")\n",
    "print_counters(counters_euc)\n",
    "\n",
    "print(\"Cosine Similarity Results:\")\n",
    "print_counters(counters_cos)\n",
    "\n",
    "# Extract results for visualization\n",
    "(methods, correct_sface_euc, incorrect_sface_euc, correct_sface_cos, incorrect_sface_cos, correct_facenet_euc, incorrect_facenet_euc, correct_facenet_cos, incorrect_facenet_cos) = extract_results(counters_euc)\n",
    "\n",
    "# Visualize the results\n",
    "visualize_results(methods, correct_sface_euc, incorrect_sface_euc, correct_sface_cos, incorrect_sface_cos, correct_facenet_euc, incorrect_facenet_euc, correct_facenet_cos, incorrect_facenet_cos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dfd6b5-7d11-4b2c-8075-05fbbea36e7e",
   "metadata": {},
   "source": [
    "below will be the functions to compare the execution time of (Facenet, SFace) x (Euclidean, Cosine) X (no quantisation, Tensorflow, scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555b6b93-8603-4e8f-a79c-9fa3b38fa0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your experiments\n",
    "experiments = [\n",
    "    {\"n\": 1000, \"get_embedding_func\": bs.get_embedding_facenet, \"quantize_func\": None, \"distance_func\": bs.get_cos_dist_numpy, \"quantize\": False},\n",
    "    {\"n\": 1000, \"get_embedding_func\": bs.get_embedding_facenet, \"quantize_func\": None, \"distance_func\": bs.euclidean_distance, \"quantize\": False},\n",
    "    {\"n\": 1000, \"get_embedding_func\": bs.get_embedding_facenet, \"quantize_func\": qt.scalar_quantisation_percentile, \"distance_func\": bs.get_cos_dist_numpy, \"quantize\": True},\n",
    "    {\"n\": 1000, \"get_embedding_func\": bs.get_embedding_facenet, \"quantize_func\": qt.scalar_quantisation_percentile, \"distance_func\": bs.euclidean_distance, \"quantize\": True},\n",
    "    {\"n\": 1000, \"get_embedding_func\": bs.get_embedding_facenet, \"quantize_func\": qt.quantize_tensor, \"distance_func\": bs.get_cos_dist_numpy, \"quantize\": True},\n",
    "    {\"n\": 1000, \"get_embedding_func\": bs.get_embedding_facenet, \"quantize_func\": qt.quantize_tensor, \"distance_func\": bs.euclidean_distance, \"quantize\": True},\n",
    "    {\"n\": 1000, \"get_embedding_func\": bs.get_embedding, \"quantize_func\": None, \"distance_func\": bs.get_cos_dist_numpy, \"quantize\": False},\n",
    "    {\"n\": 1000, \"get_embedding_func\": bs.get_embedding, \"quantize_func\": None, \"distance_func\": bs.euclidean_distance, \"quantize\": False},\n",
    "    {\"n\": 1000, \"get_embedding_func\": bs.get_embedding, \"quantize_func\": qt.scalar_quantisation_percentile, \"distance_func\": bs.get_cos_dist_numpy, \"quantize\": True},\n",
    "    {\"n\": 1000, \"get_embedding_func\": bs.get_embedding, \"quantize_func\": qt.scalar_quantisation_percentile, \"distance_func\": bs.euclidean_distance, \"quantize\": True},\n",
    "    {\"n\": 1000, \"get_embedding_func\": bs.get_embedding, \"quantize_func\": qt.quantize_tensor, \"distance_func\": bs.get_cos_dist_numpy, \"quantize\": True},\n",
    "    {\"n\": 1000, \"get_embedding_func\": bs.get_embedding, \"quantize_func\": qt.quantize_tensor, \"distance_func\": bs.euclidean_distance, \"quantize\": True},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5550b485-4921-417d-a6d3-6c462505edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(n, get_embedding_func, quantize_func, distance_func, quantize=False):\n",
    "    execution_times = []\n",
    "\n",
    "    for _ in range(n):\n",
    "        a, b, imga, imgb,n = pairs[_]\n",
    "        start_time = time.time()\n",
    "        a = get_embedding_func(imga)\n",
    "        b = get_embedding_func(imgb)\n",
    "        \n",
    "        if quantize:\n",
    "            a = quantize_func(a)\n",
    "            b = quantize_func(b)\n",
    "        \n",
    "        if distance_func == bs.get_cos_dist_numpy:\n",
    "            a = a / np.linalg.norm(a)\n",
    "            b = b / np.linalg.norm(b)\n",
    "        \n",
    "        distance_func(a, b)\n",
    "        end_time = time.time()\n",
    "\n",
    "        execution_time = end_time - start_time\n",
    "        execution_times.append(execution_time)\n",
    "    \n",
    "    return execution_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ee4acf-7cc2-4333-956e-d11348761dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all experiments\n",
    "results = {}\n",
    "for i, experiment in enumerate(experiments):\n",
    "    key = f\"experiment_{i+1}\"\n",
    "    results[key] = run_experiment(**experiment)\n",
    "    print(f\"{key} completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ec8d00-d96f-42e1-80e0-66eefa607dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary with experiment names for readability\n",
    "experiment_names = {\n",
    "    \"experiment_1\": \"avg_execution_times_no_quantisation_facenet_cos\",\n",
    "    \"experiment_2\": \"avg_execution_times_no_quantisation_facenet_ed\",\n",
    "    \"experiment_3\": \"avg_execution_times_scalar_quantisation_facenet_cos\",\n",
    "    \"experiment_4\": \"avg_execution_times_scalar_quantisation_facenet_ed\",\n",
    "    \"experiment_5\": \"avg_execution_times_tensorflow_quantisation_facenet_cos\",\n",
    "    \"experiment_6\": \"avg_execution_times_tensorflow_quantisation_facenet_ed\",\n",
    "    \"experiment_7\": \"avg_execution_times_no_quantisation_sface_cos\",\n",
    "    \"experiment_8\": \"avg_execution_times_no_quantisation_sface_ed\",\n",
    "    \"experiment_9\": \"avg_execution_times_scalar_quantisation_sface_cos\",\n",
    "    \"experiment_10\": \"avg_execution_times_scalar_quantisation_sface_ed\",\n",
    "    \"experiment_11\": \"avg_execution_times_tensorflow_quantisation_sface_cos\",\n",
    "    \"experiment_12\": \"avg_execution_times_tensorflow_quantisation_sface_ed\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6051591c-1fac-4c71-a529-5c9c0bed5f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print the average execution times\n",
    "for key, name in experiment_names.items():\n",
    "    avg_time = statistics.mean(results[key])\n",
    "    print(f\"{name} = {avg_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1a2410-8b89-4cbd-bc4d-4e94810c69fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define quantization functions\n",
    "quantization_functions = {\n",
    "    \"scalar_quantisation_max\": qt.scalar_quantisation_max,\n",
    "    \"scalar_quantisation_percentile\": qt.scalar_quantisation_percentile,\n",
    "    \"scalar_quantisation_tensorrt\": qt.scalar_quantisation_tensorrt\n",
    "}\n",
    "\n",
    "# Define your experiments\n",
    "experiments = []\n",
    "\n",
    "embedding_functions = [bs.get_embedding_facenet, bs.get_embedding]\n",
    "distance_functions = [bs.get_cos_dist_numpy, bs.euclidean_distance]\n",
    "\n",
    "# Add experiments for no quantization\n",
    "for get_embedding_func in embedding_functions:\n",
    "    for distance_func in distance_functions:\n",
    "        experiments.append({\n",
    "            \"n\": 1000,\n",
    "            \"get_embedding_func\": get_embedding_func,\n",
    "            \"quantize_func\": None,\n",
    "            \"distance_func\": distance_func,\n",
    "            \"quantize\": False\n",
    "        })\n",
    "\n",
    "# Add experiments for tensor quantization\n",
    "for get_embedding_func in embedding_functions:\n",
    "    for distance_func in distance_functions:\n",
    "        experiments.append({\n",
    "            \"n\": 1000,\n",
    "            \"get_embedding_func\": get_embedding_func,\n",
    "            \"quantize_func\": qt.quantize_tensor,\n",
    "            \"distance_func\": distance_func,\n",
    "            \"quantize\": True\n",
    "        })\n",
    "\n",
    "# Add experiments for each scalar quantization method\n",
    "for get_embedding_func in embedding_functions:\n",
    "    for distance_func in distance_functions:\n",
    "        for name, quant_func in quantization_functions.items():\n",
    "            experiments.append({\n",
    "                \"n\": 1000,\n",
    "                \"get_embedding_func\": get_embedding_func,\n",
    "                \"quantize_func\": quant_func,\n",
    "                \"distance_func\": distance_func,\n",
    "                \"quantize\": True\n",
    "            })\n",
    "\n",
    "def run_experiment(n, get_embedding_func, quantize_func, distance_func, quantize=False):\n",
    "    execution_times = []\n",
    "\n",
    "    for _ in range(n):\n",
    "        a, b, imga, imgb, n = pairs[_]\n",
    "        start_time = time.time()\n",
    "        a = get_embedding_func(imga)\n",
    "        b = get_embedding_func(imgb)\n",
    "        \n",
    "        if quantize:\n",
    "            a = quantize_func(a)\n",
    "            b = quantize_func(b)\n",
    "        \n",
    "        if distance_func == bs.get_cos_dist_numpy:\n",
    "            a = a / np.linalg.norm(a)\n",
    "            b = b / np.linalg.norm(b)\n",
    "        \n",
    "        distance_func(a, b)\n",
    "        end_time = time.time()\n",
    "\n",
    "        execution_time = end_time - start_time\n",
    "        execution_times.append(execution_time)\n",
    "    \n",
    "    return execution_times\n",
    "\n",
    "# Run all experiments\n",
    "results = {}\n",
    "for i, experiment in enumerate(experiments):\n",
    "    key = f\"experiment_{i+1}\"\n",
    "    results[key] = run_experiment(**experiment)\n",
    "    print(f\"{key} completed\")\n",
    "\n",
    "# Define a dictionary with experiment names for readability\n",
    "experiment_names = {\n",
    "    \"experiment_1\": \"avg_execution_times_no_quantisation_facenet_cos\",\n",
    "    \"experiment_2\": \"avg_execution_times_no_quantisation_facenet_ed\",\n",
    "    \"experiment_3\": \"avg_execution_times_no_quantisation_sface_cos\",\n",
    "    \"experiment_4\": \"avg_execution_times_no_quantisation_sface_ed\",\n",
    "    \"experiment_5\": \"avg_execution_times_tensor_quantisation_facenet_cos\",\n",
    "    \"experiment_6\": \"avg_execution_times_tensor_quantisation_facenet_ed\",\n",
    "    \"experiment_7\": \"avg_execution_times_tensor_quantisation_sface_cos\",\n",
    "    \"experiment_8\": \"avg_execution_times_tensor_quantisation_sface_ed\",\n",
    "    \"experiment_9\": \"avg_execution_times_scalar_quantisation_max_facenet_cos\",\n",
    "    \"experiment_10\": \"avg_execution_times_scalar_quantisation_max_facenet_ed\",\n",
    "    \"experiment_11\": \"avg_execution_times_scalar_quantisation_max_sface_cos\",\n",
    "    \"experiment_12\": \"avg_execution_times_scalar_quantisation_max_sface_ed\",\n",
    "    \"experiment_13\": \"avg_execution_times_scalar_quantisation_percentile_facenet_cos\",\n",
    "    \"experiment_14\": \"avg_execution_times_scalar_quantisation_percentile_facenet_ed\",\n",
    "    \"experiment_15\": \"avg_execution_times_scalar_quantisation_percentile_sface_cos\",\n",
    "    \"experiment_16\": \"avg_execution_times_scalar_quantisation_percentile_sface_ed\",\n",
    "    \"experiment_17\": \"avg_execution_times_scalar_quantisation_tensorrt_facenet_cos\",\n",
    "    \"experiment_18\": \"avg_execution_times_scalar_quantisation_tensorrt_facenet_ed\",\n",
    "    \"experiment_19\": \"avg_execution_times_scalar_quantisation_tensorrt_sface_cos\",\n",
    "    \"experiment_20\": \"avg_execution_times_scalar_quantisation_tensorrt_sface_ed\"\n",
    "}\n",
    "\n",
    "# Calculate and print the average execution times\n",
    "for key, name in experiment_names.items():\n",
    "    avg_time = statistics.mean(results[key])\n",
    "    print(f\"{name} = {avg_time}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
